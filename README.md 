ğŸ“˜ Real-Time Sales Data Pipeline using Kafka, PostgreSQL & Python
ğŸ“Œ Project Overview

This project demonstrates a complete real-time data engineering pipeline built using:

Apache Kafka â†’ real-time message streaming

Python Producer â†’ generates continuous sales data

Python Consumer â†’ consumes data & stores into database

PostgreSQL â†’ structured data storage

Pandas + Matplotlib â†’ analytics and visualization

This pipeline simulates real-world streaming systems used in companies like:
Netflix, Uber, Amazon, Flipkart, Swiggy, Zomato, BigBasket, Paytm, etc.

ğŸš€ Architecture

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Python Producer â”‚ ----> â”‚     Kafka Topic   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Python Consumer  â”‚ ----> â”‚    PostgreSQL     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚      Analytics (Pandas + Matplotlib)    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ§© Technologies Used

| Component            | Technology            |
| -------------------- | --------------------- |
| Real-Time Streaming  | **Apache Kafka**      |
| Data Generation      | Python (Faker)        |
| Data Ingestion       | Python Kafka Consumer |
| Storage              | PostgreSQL            |
| Visualization        | Pandas, Matplotlib    |
| Programming Language | Python 3.13           |


ğŸ“‚ Project Structure

sales_kafka_project/
â”‚â”€â”€ sales_producer.py
â”‚â”€â”€ sales_consumer.py
â”‚â”€â”€ sales_dashboard.py
â”‚â”€â”€ README.md

1. Python Producer (Real-Time Data Generation)

sales_producer.py generates streaming data:

Product name

Quantity

Price

Timestamp

Then sends it to Kafka topic: sales-topic

2. Python Consumer (Ingestion Layer)

sales_consumer.py listens to sales-topic and inserts data into PostgreSQL table:

CREATE TABLE sales_data (
    sale_id SERIAL PRIMARY KEY,
    product_name VARCHAR(50),
    quantity INT,
    price NUMERIC(10,2),
    timestamp TIMESTAMP
);

3. PostgreSQL Storage

Data is inserted into:

Database â†’ salesdb

Table â†’ sales_data


4. Analytics Dashboard

sales_dashboard.py performs:

Daily Revenue Trend

Top Selling Products

Daily Quantity Sold

Price Distribution

Using Pandas + Matplotlib.


ğŸ›  How to Run the Project
âœ” Step 1 â€” Start Zookeeper

cd ~/Kafka
bin/zookeeper-server-start.sh config/zookeeper.properties


âœ” Step 2 â€” Start Kafka Broker
cd ~/Kafka
bin/kafka-server-start.sh config/server.properties

âœ” Step 3 â€” Create Topic
bin/kafka-topics.sh --create --topic sales-topic --bootstrap-server localhost:9092

âœ” Step 4 â€” Run Producer
cd ~/sales_kafka_project
python3 sales_producer.py


Youâ€™ll see:

Sent: {'product_name': 'Mobile', 'quantity': 3, ...}

âœ” Step 5 â€” Run Consumer
cd ~/sales_kafka_project
python3 sales_consumer.py


Youâ€™ll see:

Inserted: {'product_name': 'Mobile', 'quantity': 3, ...}

âœ” Step 6 â€” Run Dashboard
python3 sales_dashboard.py


Shows:

Revenue graph

Quantity trend

Product bar chart

Price distribution





Complete Flow (Very Simple Explanation)
Python Producer (generates fake sales)
        â†“
Kafka Topic (real-time stream)
        â†“
Kafka Consumer (Python)
        â†“
PostgreSQL (database)
        â†“
Pandas + Matplotlib Dashboard
